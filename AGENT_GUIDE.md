# Gu√≠a del Agente Recomendador - GraphRAG

Sistema de recomendaci√≥n de campus universitarios usando Metro de Madrid con comparaci√≥n Baseline LLM vs GraphRAG para benchmark ICLR 2026.

---

## Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    USUARIO                                  ‚îÇ
‚îÇ              (Consulta en lenguaje natural)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                           ‚îÇ
        ‚ñº                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   BASELINE    ‚îÇ          ‚îÇ     GRAPHRAG       ‚îÇ
‚îÇ   (Sin RAG)   ‚îÇ          ‚îÇ  (Con contexto BD) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                            ‚îÇ
        ‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                   ‚îÇ                 ‚îÇ
        ‚îÇ                   ‚ñº                 ‚ñº
        ‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ          ‚îÇ   MongoDB    ‚îÇ  ‚îÇ    Neo4j     ‚îÇ
        ‚îÇ          ‚îÇ   (Campus)   ‚îÇ  ‚îÇ   (Rutas)    ‚îÇ
        ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                   ‚îÇ                 ‚îÇ
        ‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                            ‚îÇ
        ‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                   ‚îÇ    Contexto     ‚îÇ
        ‚îÇ                   ‚îÇ  Estructurado   ‚îÇ
        ‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                            ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ      LLM       ‚îÇ
            ‚îÇ (GPT/Claude)   ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   RESPUESTA    ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Instalaci√≥n y Configuraci√≥n

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Configurar variables de entorno

```bash
cp .env.example .env
```

Edita `.env`:

```env
# Bases de datos
MONGODB_URI=mongodb://localhost:27017/
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# LLM (opcional - sin configurar usa MockProvider)
OPENAI_API_KEY=sk-...
# O
ANTHROPIC_API_KEY=sk-ant-...
```

### 3. Cargar datos en las bases de datos

```bash
# MongoDB
cd scripts/mongodb && python load_data.py

# Neo4j
cd scripts/neo4j && python load_data.py
```

---

## Uso B√°sico del Agente

### Ejemplo 1: Usar MockProvider (sin API)

```python
from src.agent import MetroCampusRecommender

# Crear recomendador con proveedor simulado
recommender = MetroCampusRecommender(verbose=True)

try:
    # Consulta de ejemplo
    query = "Desde Sol, ¬øcu√°l es el mejor campus para estudiar el M√°ster en Inteligencia Artificial?"

    # Comparar ambos m√©todos
    results = recommender.compare_methods(query)

    # Ver resultados
    print("\n=== BASELINE ===")
    print(results['baseline']['response'])

    print("\n=== GRAPHRAG ===")
    print(results['graphrag']['response'])

finally:
    recommender.close()
```

### Ejemplo 2: Usar OpenAI GPT-4

```python
from src.agent import MetroCampusRecommender, create_llm_provider

# Crear proveedor de OpenAI
llm = create_llm_provider("openai", model="gpt-4")

# Crear recomendador
recommender = MetroCampusRecommender(
    llm_provider=llm,
    verbose=True
)

try:
    query = "Desde Atocha, ¬øc√≥mo llego a la UCM?"
    result = recommender.graphrag_recommendation(query)

    print(result['response'])

finally:
    recommender.close()
```

### Ejemplo 3: Usar Claude (Anthropic)

```python
from src.agent import MetroCampusRecommender, create_llm_provider

# Crear proveedor de Claude
llm = create_llm_provider("anthropic", model="claude-3-5-sonnet-20241022")

recommender = MetroCampusRecommender(
    llm_provider=llm,
    verbose=True
)

try:
    query = "Desde Pr√≠ncipe P√≠o, busco el Grado en Ingenier√≠a de Datos"
    result = recommender.baseline_llm(query)

    print(result['response'])

finally:
    recommender.close()
```

### Ejemplo 4: Usar Modelo Local (Ollama)

```python
from src.agent import MetroCampusRecommender, create_llm_provider

# Crear proveedor local (requiere Ollama corriendo)
llm = create_llm_provider("local", model="llama3", base_url="http://localhost:11434")

recommender = MetroCampusRecommender(
    llm_provider=llm,
    verbose=True
)

try:
    query = "¬øQu√© campus de la UPM est√°n cerca de Moncloa?"
    result = recommender.graphrag_recommendation(query)

    print(result['response'])

finally:
    recommender.close()
```

---

## Pipeline GraphRAG (4 Fases)

### Fase 1: Extracci√≥n de Entidades

El sistema extrae autom√°ticamente:
- **Estaci√≥n de origen**: "desde Sol", "estoy en Atocha"
- **Estudio buscado**: "M√°ster en IA", "Grado en Ingenier√≠a"

```python
# Interno - Se ejecuta autom√°ticamente
entities = recommender._extract_entities(query)
# {'estacion_origen': 'Sol', 'estudio': 'Inteligencia Artificial'}
```

### Fase 2: Recuperaci√≥n de Contexto

Consultas simult√°neas a:

**MongoDB**: Campus que ofrecen el estudio
```python
campus = recommender._search_campus_mongodb("Inteligencia Artificial")
# Retorna: [{nombre: "UCM", estudios: [...], estaciones_cercanas: [...]}]
```

**Neo4j**: Rutas √≥ptimas con `shortestPath()`
```python
rutas = recommender._calculate_routes_neo4j("Sol", campus_list)
# Retorna: [{campus: "UCM", ruta: [...], num_cambios_linea: 1, ...}]
```

### Fase 3: Aumentaci√≥n del Prompt

Construcci√≥n de prompt estructurado:

```
DATOS REALES EXTRA√çDOS DE LA BASE DE DATOS:
============================================================

CONSULTA DEL USUARIO:
Desde Sol, ¬øcu√°l es el mejor campus para estudiar el M√°ster en IA?

ENTIDADES IDENTIFICADAS:
- Estaci√≥n de origen: Sol
- Estudio buscado: Inteligencia Artificial

CAMPUS QUE OFRECEN ESTE ESTUDIO:
1. Ciudad Universitaria (UCM)
   - M√°ster en Inteligencia Artificial (MASTER)
     Cr√©ditos: 60

RUTAS CALCULADAS DESDE Sol:
1. Hacia Ciudad Universitaria (UCM)
   Estaci√≥n destino: Ciudad Universitaria (principal)
   Distancia: 8 estaciones
   Transbordos: 1
   L√≠neas usadas: L1, L6
   Ruta: Sol ‚Üí Tribunal ‚Üí Alonso Mart√≠nez ‚Üí ... ‚Üí Ciudad Universitaria

INSTRUCCIONES:
Bas√°ndote √öNICAMENTE en los datos anteriores...
```

### Fase 4: Generaci√≥n

El LLM genera respuesta bas√°ndose **estrictamente en el contexto** proporcionado.

---

## Ejecutar el Benchmark

### Benchmark Completo (10 consultas desaf√≠o)

```bash
cd src/agent
python evaluate.py
```

**Salida esperada:**

```
================================================================================
BENCHMARK: BASELINE vs GRAPHRAG
================================================================================
Total de consultas: 10

[1/10] Procesando consulta 1...
Dificultad: medium
Query: Desde Sol, ¬øcu√°l es el mejor campus para estudiar el M√°ster en IA?
  ‚úì Baseline v√°lido: True
  ‚úì GraphRAG v√°lido: True
  ‚Ä¢ Campus encontrados (GraphRAG): 3
  ‚Ä¢ Rutas calculadas (GraphRAG): 4

[2/10] Procesando consulta 2...
...

================================================================================
RESUMEN DE RESULTADOS
================================================================================

üìä TASA DE √âXITO:
  ‚Ä¢ Baseline:  60.0%
  ‚Ä¢ GraphRAG:  90.0%

üîÑ TRANSBORDOS PROMEDIO:
  ‚Ä¢ Baseline:  1.20
  ‚Ä¢ GraphRAG:  0.80

üö® ALUCINACIONES DETECTADAS:
  ‚Ä¢ Baseline:  5
  ‚Ä¢ GraphRAG:  1

‚úÖ GANADOR: GraphRAG

üíæ Resultados guardados en: results/experiments.json
```

### Ejecutar consultas espec√≠ficas

```python
from src.agent.evaluate import BenchmarkEvaluator, CHALLENGE_QUERIES
from src.agent import MetroCampusRecommender, create_llm_provider

# Crear recomendador
llm = create_llm_provider("mock")  # O "openai", "anthropic"
recommender = MetroCampusRecommender(llm_provider=llm)

# Crear evaluador
evaluator = BenchmarkEvaluator(recommender, verbose=True)

# Ejecutar solo consultas f√°ciles
easy_queries = [q for q in CHALLENGE_QUERIES if q['difficulty'] == 'easy']
results = evaluator.run_benchmark(queries=easy_queries)

# Ver resumen
evaluator.print_summary(results)

recommender.close()
```

---

## M√©tricas de Evaluaci√≥n

### Success Rate (Tasa de √âxito)

**Criterios**:
- ‚úÖ Menciona la estaci√≥n de origen correcta
- ‚úÖ Menciona al menos un campus v√°lido
- ‚úÖ La ruta es coherente

```python
# Autom√°tico en evaluate.py
metrics = EvaluationMetrics.validate_route(response, expected)
print(f"V√°lido: {metrics['is_valid']}")
```

### N√∫mero de Transbordos

**Detecci√≥n autom√°tica** de patrones:
- "1 transbordo"
- "sin transbordo"
- "directo"
- "cambio de l√≠nea"

```python
num_transbordos = metrics['num_transbordos_mencionados']
```

### Alucinaciones Detectadas

**Para Baseline**:
- Menciona estaciones/campus que no existen
- Usa lenguaje incierto: "probablemente", "puede que"

**Para GraphRAG**:
- Menciona campus NO presentes en el contexto
- Inventa rutas no calculadas

```python
# GraphRAG espec√≠fico
hallucinations = EvaluationMetrics.detect_hallucinations_graphrag(
    response,
    context_data
)
```

---

## Consultas Desaf√≠o Incluidas

| ID | Dificultad | Descripci√≥n                          | Requiere Transbordo |
|----|------------|--------------------------------------|---------------------|
| 1  | Medium     | Sol ‚Üí M√°ster IA                     | S√≠ (L1‚ÜíL6)         |
| 2  | Medium     | Atocha ‚Üí Grado Ciencia de Datos     | S√≠ (L1‚ÜíL6)         |
| 3  | Hard       | Chamart√≠n ‚Üí M√°ster Big Data         | S√≠ (L10‚ÜíL6)        |
| 4  | Easy       | Pr√≠ncipe P√≠o ‚Üí UPM + IA             | No (L6 directo)    |
| 5  | Easy       | Moncloa ‚Üí Ing. Inform√°tica          | No (L6 directo)    |
| 6  | Hard       | Pac√≠fico ‚Üí UC3M + Machine Learning  | S√≠ (L6‚ÜíL3)         |
| 7  | Hard       | Sol ‚Üí URJC + Cloud Computing        | S√≠ (L1‚ÜíL10)        |
| 8  | Easy       | Ciudad Univ. ‚Üí M√°ster Rob√≥tica      | No (L6 circular)   |
| 9  | Medium     | Plaza Castilla ‚Üí Campus UCM         | S√≠ (L1‚ÜíL6)         |
| 10 | Easy       | Cuatro Caminos ‚Üí M√°ster Ciberseg.   | No (L6 directo)    |

---

## Resultados del Benchmark

Los resultados se guardan en `results/experiments.json`:

```json
{
  "metadata": {
    "timestamp": "2025-12-21T18:30:00",
    "total_queries": 10,
    "llm_provider": "MockProvider"
  },
  "results": [
    {
      "challenge_id": 1,
      "query": "Desde Sol, ¬øcu√°l es el mejor campus para...",
      "baseline_response": "...",
      "graphrag_response": "...",
      "baseline_metrics": {
        "is_valid": true,
        "num_transbordos_mencionados": 1
      },
      "graphrag_metrics": {
        "is_valid": true,
        "num_transbordos_mencionados": 1
      },
      "graphrag_context": {
        "campus_found": 3,
        "routes_calculated": 4
      }
    }
  ],
  "summary": {
    "success_rates": {
      "baseline_success_rate": 0.6,
      "graphrag_success_rate": 0.9
    },
    "avg_transbordos_baseline": 1.2,
    "avg_transbordos_graphrag": 0.8,
    "total_hallucinations_baseline": 5,
    "total_hallucinations_graphrag": 1
  }
}
```

---

## Hip√≥tesis del Benchmark (ICLR 2026)

### Hip√≥tesis Principal

> **GraphRAG mejorar√° la precisi√≥n en recomendaciones multiobjetivo (distancia + cambios de l√≠nea + oferta acad√©mica) en comparaci√≥n con Baseline LLM**

### M√©tricas Esperadas

| M√©trica                    | Baseline | GraphRAG | Mejora Esperada |
|----------------------------|----------|----------|-----------------|
| Tasa de √âxito              | 50-70%   | 85-95%   | +25-35%         |
| Transbordos Correctos      | 40-60%   | 80-90%   | +40%            |
| Alucinaciones              | 20-30%   | 5-10%    | -60%            |
| Campus Correctos           | 60-75%   | 90-100%  | +30%            |

### Variables Controladas

- Mismo LLM para ambos m√©todos
- Mismas consultas de prueba
- Misma temperatura (0.3)
- Mismo conjunto de datos

---

## Troubleshooting

### Error: "OPENAI_API_KEY no configurada"

```bash
# Usar MockProvider en desarrollo
llm = create_llm_provider("mock")

# O configurar API key
export OPENAI_API_KEY=sk-...
```

### Error: Conexi√≥n a MongoDB/Neo4j

```bash
# Verificar que las BD est√°n corriendo
mongosh  # MongoDB
cypher-shell  # Neo4j

# O actualizar URIs en .env
```

### MockProvider devuelve respuestas gen√©ricas

Esto es normal. MockProvider es para testing. Para resultados reales:

```python
llm = create_llm_provider("openai", model="gpt-4")
# O
llm = create_llm_provider("anthropic", model="claude-3-5-sonnet-20241022")
```

---

## Contribuir al Benchmark

Para a√±adir nuevas consultas desaf√≠o:

```python
# En src/agent/evaluate.py

CHALLENGE_QUERIES.append({
    "id": 11,
    "query": "Tu consulta aqu√≠",
    "expected": {
        "estacion_origen": "Origen",
        "estudio": "Estudio",
        "campus_validos": ["Campus 1", "Campus 2"],
        "requiere_transbordo": True/False,
        "lineas_validas": [[1, 6], [3]]
    },
    "difficulty": "easy/medium/hard"
})
```

---

## Referencias

- [Documentaci√≥n MongoDB](https://docs.mongodb.com/)
- [Documentaci√≥n Neo4j Cypher](https://neo4j.com/docs/cypher-manual/)
- [OpenAI API](https://platform.openai.com/docs)
- [Anthropic Claude API](https://docs.anthropic.com/)
- [Ollama (modelos locales)](https://ollama.ai/)

---

## Autores

Proyecto desarrollado para la asignatura de **Bases de Datos No Relacionales**
Grado en Ciencia e Ingenier√≠a de Datos - Universidad Rey Juan Carlos
Curso 2025/2026

**Benchmark preparado para ICLR 2026**
